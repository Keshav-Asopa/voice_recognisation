{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "from sklearn.mixture import GMM \n",
    "from featureextraction import extract_features\n",
    "import speech_recognition as sr\n",
    "import pickle\n",
    "import shutil\n",
    "import os \n",
    "import numpy as np\n",
    "import time\n",
    "import pyaudio\n",
    "import wave\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making data runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_audio_files():\n",
    "    global source1\n",
    "    for i in range(1,8):\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 2\n",
    "        RATE = 44100\n",
    "        CHUNK = 1024\n",
    "        RECORD_SECONDS = 2\n",
    "        WAVE_OUTPUT_FILENAME = \"file\"+str(i)+\".wav\"\n",
    "\n",
    "        audio = pyaudio.PyAudio()\n",
    "\n",
    "        # start Recording\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "        print(\"say again\")\n",
    "        print(\"recording...\")\n",
    "        frames = []\n",
    "\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "        print(\"finished recording\")\n",
    "\n",
    "        # stop Recording\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "\n",
    "        #Saving the file\n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "        \n",
    "        time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making_audio_files()\n",
    "def shifting_of_files():\n",
    "    for i in range(1,8):\n",
    "        #Moving file from one location to other location\n",
    "        shutil.move('/home/keshav/Desktop/voice_recognisation/file'+str(i)+'.wav', '/home/keshav/Desktop/voice_recognisation/trainingData/user-1/file'+str(i)+'.wav')\n",
    "#training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def training_model():\n",
    "    #path to training data\n",
    "    source = \"trainingData/\"   \n",
    "\n",
    "    #path where training speakers will be saved\n",
    "    dest = \"Speakers_models/\"\n",
    "    train_file = \"trainingDataPath.txt\"        \n",
    "    file_paths = open(train_file,'r')\n",
    "    print(type(file_paths))\n",
    "\n",
    "    count = 1\n",
    "    # Extracti(ng features for each speaker (5 files per speakers)\n",
    "    features = np.asarray(())\n",
    "\n",
    "    print(file_paths)\n",
    "    for path in file_paths:\n",
    "        path = path.strip()   \n",
    "        print(path)\n",
    "\n",
    "        # read the audio\n",
    "        sr,audio = read(source + path)\n",
    "\n",
    "        # extract 40 dimensional MFCC & delta MFCC features\n",
    "        vector   = extract_features(audio,sr)\n",
    "\n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features, vector))\n",
    "\n",
    "        if count == 7:    \n",
    "\n",
    "            gmm = GMM(n_components = 16, n_iter = 200, covariance_type='diag',n_init = 3)        \n",
    "\n",
    "            gmm.fit(features)\n",
    "\n",
    "            # dumping the trained gaussian model\n",
    "            picklefile = path.split(\"-\")[0]+\".gmm\"\n",
    "            print(picklefile)\n",
    "\n",
    "            pickle.dump(gmm,open(dest + picklefile,'wb'))\n",
    "            print('+ modeling completed for speaker:',picklefile,\" with data point = \",features.shape)    \n",
    "            features = np.asarray(())\n",
    "            count = 0\n",
    "            break\n",
    "        count = count + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding max and min value of log_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_log_likelihood():\n",
    "    global maximum, minimum\n",
    "    #path to training data\n",
    "    source   = \"trainingData/\"\n",
    "\n",
    "    #path where training speakers will be saved\n",
    "    modelpath = \"Speakers_models/\"\n",
    "\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in\n",
    "                 os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "\n",
    "    #Load the Gaussian gender Models\n",
    "    models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "    speakers   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname\n",
    "                 in gmm_files]\n",
    "\n",
    "    error = 0\n",
    "    total_sample = 0.0\n",
    "    train_file = \"trainingDataPath.txt\"\n",
    "    file_paths = open(train_file,'r')\n",
    "    f = 0\n",
    "    # Read the test directory and get the list of test audio files\n",
    "    list1 =[]\n",
    "    for path in file_paths:\n",
    "        total_sample += 1.0\n",
    "        path = path.strip()\n",
    "        print(path)\n",
    "    #print(\"Testing Audio : \", path)\n",
    "        sr,audio = read(source + path)\n",
    "        vector   = extract_features(audio,sr)\n",
    "\n",
    "        log_likelihood = np.zeros(len(models))\n",
    "        for i in range(len(models)):\n",
    "            gmm    = models[i]  #checking with each model one by one\n",
    "            scores = np.array(gmm.score(vector))\n",
    "            log_likelihood[i] = scores.sum()\n",
    "            f += 1\n",
    "            list1.append(scores.sum())\n",
    "\n",
    "        print(log_likelihood[i])\n",
    "        if (f == 7):\n",
    "            break\n",
    "\n",
    "    print(len(list1))\n",
    "    maximum = max(list1)\n",
    "    minimum = min(list1)\n",
    "    return maximum, minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_runtime():\n",
    "    \n",
    "    global source1\n",
    "\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 2\n",
    "    WAVE_OUTPUT_FILENAME = \"file.wav\"\n",
    " \n",
    "    audio = pyaudio.PyAudio()\n",
    " \n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "    print(\"say again\")\n",
    "    print(\"recording...\")\n",
    "    frames = []\n",
    " \n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"finished recording\")\n",
    "\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    \n",
    "    #Saving the file\n",
    "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "\n",
    "    #Moving file from one location to other location\n",
    "    shutil.move('/home/keshav/Desktop/voice_recognisation/file.wav', '/home/keshav/Desktop/voice_recognisation/SampleData/file.wav')\n",
    "    \n",
    "    #time for prediction\n",
    "    predict_file()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file():\n",
    "    global source1, maximum, minimum\n",
    "\n",
    "    sr,audio = read(source1)\n",
    "    vector   = extract_features(audio,sr)\n",
    "    #path to training data\n",
    "    source   = \"SampleData/\"   \n",
    "\n",
    "    #path where training speakers will be saved\n",
    "    modelpath = \"Speakers_models/\"\n",
    "\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in \n",
    "              os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "    #Load the Gaussian gender Models\n",
    "    models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "    speakers   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname \n",
    "              in gmm_files]\n",
    "    \n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "    for i in range(len(models)):\n",
    "        gmm    = models[i]  #checking with each model one by one\n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "    print(log_likelihood[i])\n",
    "    if(minimum < log_likelihood[i] < maximum):\n",
    "        winner = np.argmax(log_likelihood)\n",
    "        print(\"\\tdetected as - \", speakers[winner])\n",
    "        check_command(speakers,winner)\n",
    "    else:\n",
    "        print('not authorise please try again')\n",
    "        testing_runtime()\n",
    "        time.sleep(0.5)\n",
    "        #winner = None\n",
    "    time.sleep(1.0)\n",
    "\n",
    "\n",
    "def check_command(speakers,winner):\n",
    "    import speech_recognition as sr\n",
    "    global source1\n",
    "    \n",
    "    #Check for authentication\n",
    "    if speakers[winner] == 'user':\n",
    "        AUDIO_FILE = source1    \n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(AUDIO_FILE) as source:\n",
    "            audio = r.listen(source)\n",
    "        try:\n",
    "            command = r.recognize_google(audio).lower()\n",
    "            print('You said: ' + command + '\\n')\n",
    "        #loop back to continue to listen for commands if unrecognizable speech is received\n",
    "        except sr.UnknownValueError:\n",
    "            print('....')\n",
    "\n",
    "    if  'unlock the system' in command:\n",
    "        os.system('cheese')\n",
    "    else:\n",
    "        print('keyword does not match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            press 0 to retrain the model\n",
      "            press 1 to unlock the system by your trained voice\n",
      "          \n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'getting_log_likelihood' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0c550746930e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training is Completed........\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetting_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtesting_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getting_log_likelihood' is not defined"
     ]
    }
   ],
   "source": [
    "global source1, maximum, minimum\n",
    "source1 = '/home/keshav/Desktop/voice_recognisation/SampleData/file.wav'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('''\n",
    "            press 0 to retrain the model\n",
    "            press 1 to unlock the system by your trained voice\n",
    "          '''\n",
    "         )\n",
    "    choice = int(input())\n",
    "    if choice == 0:\n",
    "        making_audio_files()\n",
    "        shifting_of_files()\n",
    "        print(\"Your Model is Training ........\")\n",
    "        training_model()\n",
    "        maximum, minimum = getting_log_likelihood()\n",
    "        print(\"Training is Completed........\")\n",
    "    elif choice == 1:\n",
    "        maximum, minimum = getting_log_likelihood()\n",
    "        testing_runtime()\n",
    "    else:\n",
    "        print(\"wrong choice is entered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
